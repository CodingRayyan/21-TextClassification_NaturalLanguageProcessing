{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Common Challenges in NLP\n",
        "\n",
        "1. Sparsity of Data (Sparsity is a noun that means something is scattered, scanty, or lacking density):\n",
        "  - Definition: NLP models often struggle with sparse datasets where there is insufficient data to learn patterns effectively. This issue is common in languages with fewer resources or when working with specialized domains.\n",
        "  \n",
        "  - Example: Training a sentiment analysis model on a small dataset of customer reviews will lead to poor generalization and inaccurate predictions due to insufficient word occurrences.\n",
        "\n",
        "2. Ambiguity (Ambiguites means a word or expression that can be understood in two or more possible ways):\n",
        "  - Definition: Words or sentences can have multiple meanings depending on the context, making it difficult for NLP models to interpret them correctly.\n",
        "\n",
        "  - Example: The sentence \"I saw a bat in the park.\" could refer to a flying mammal or a baseball bat, and determining the correct meaning depends on the context.\n",
        "\n",
        "3. Irrelevant:\n",
        "  - Definition: NLP models often process text that contains irrelevant or redundant information, which can affect model performance.\n",
        "\n",
        "  - Example: When analyzing product reviews, customers might include personal stories or unrelated opinions, making it harder to extract meaningful insights about the product.\n",
        "\n",
        "4. Out of Vocabulary(OOV):\n",
        "  - Definition: When a model encounters words that were not present in its training data, it struggles to process them effectively.\n",
        "\n",
        "  - Example: A chatbot trained on general English conversations might fail to understand technical jargon like ‚Äúhyperparameter tuning‚Äù in a machine learning discussion.\n",
        "\n",
        "5. Noise:\n",
        "  - Definition: NLP models often deal with noisy data that includes spelling errors, special characters, informal text, or unwanted symbols.\n",
        "\n",
        "  - Example: Social media posts like ‚ÄúGooooddd morrninng!!! üòä‚òÄÔ∏è‚Äù contain extra letters, emojis, and symbols that can make sentiment analysis challenging."
      ],
      "metadata": {
        "id": "ghLsgbRUtUXW"
      }
    }
  ]
}